########## Cleaning up the output ##########

# How to use --------------------------------------------------------------
# First set the working directory, min_year and stop_words_custom (words you want filtered out)
# Then run with ctrl+shift+enter

# Packages
library(stringr)
library(RColorBrewer)
library(wordcloud)
library(ggplot2)
library(tidytext)
library(SnowballC)
library(tm)

googletranslate_login <- "C:/Users/charlie-kershaw/Documents/R/r_google_api_login.json"

folder <- paste0("Client Outputs/",company_name,"/")
if(!dir.exists(folder)){
  dir.create(folder)
}

# Minimum date
#min_year = 2017

# min_date = "01/06/2017"
# max_date = "01/06/2019"

min_date = "01/01/2017"
max_date = "01/06/2020"

min_date = as.Date(min_date,"%d/%m/%Y")
max_date = as.Date(max_date,"%d/%m/%Y")
#max_date = 01-06-2017

#clean_tibble <- review_tibble
clean_tibble <- output_tibble

clean_tibble$id <- as.numeric(rownames(clean_tibble))
clean_tibble$year <- as.numeric(substr(clean_tibble$date,nchar(clean_tibble$date)-4,nchar(clean_tibble$date)))

#OLD FORMATS THAT DON'T WORK ANY MORE FOR REFERENCE
#clean_tibble$year <- as.numeric(sub(".*, ","", clean_tibble$date)) 
# clean_tibble$position <- sub(".* Employee - ", "", clean_tibble$title)
# clean_tibble$location <- sub(".*\\ in ", "", clean_tibble$title)

# Removing reviews out of date range
clean_tibble <- clean_tibble %>% rowwise() %>% mutate(date2 = as.Date(date,"%B %d,%Y"))
clean_tibble <- filter(clean_tibble,date2 > min_date & date2 <= max_date)

# Removing duplicate reviews (for some reason it duplicates some old reviews, this removes those with duplicates in pros and cons)
clean_tibble <- subset(clean_tibble,!(duplicated(clean_tibble[,5]) & duplicated(clean_tibble[,6])))

##### TRANSLATING START #####
# library(googleLanguageR)
# library(googleAuthR)
# gl_auth(googletranslate_login)
# 
# # To check if english then translate
# clean_tibble <- clean_tibble %>% 
#   rowwise() %>%
#   mutate(language=gl_translate_detect(pros)$language) # Checking if english to avoid unnecessary translation
# 
# clean_tibble <- clean_tibble %>% 
#   mutate(pros = ifelse(language=="en",pros,gl_translate(pros,target = "en")$translatedText)) %>% # If not english, translating to english (pros)
#   mutate(cons = ifelse(language=="en",cons,gl_translate(cons,target = "en")$translatedText)) # If not english, translating to english (cons)

# --To translate all without checking
# clean_tibble <- clean_tibble %>% 
#   mutate(pros = gl_translate(pros,target = "en")$translatedText) %>% # Translating to english (pros)
#   mutate(cons = gl_translate(cons,target = "en")$translatedText) # Translating to english (cons)

##### TRANSLATING END #####


# Words to remove
stop_words_custom <- tibble(word = c("company",tolower(company_name),"low","lack","poor","en","whats","isnt","con","dont","don't","lot","lots","nicht","sehr","und","cons","pros","past","worst","terrible","bad","doesnt","left","due","top","und","bit","limited","real","didnt","india","cro","heavy","die","free","based","und","cab","von","huge","amazing","pretty","postitive","fantastic","kollegen","ist","der","ive","gute","zu","mit","cros","youre"))

########## Word Counting ##########

pros_concat <- paste(clean_tibble$pros,collapse=" ")
cons_concat <- paste(clean_tibble$cons,collapse=" ")

pros_concat_clean <- removePunctuation(tolower(pros_concat))
cons_concat_clean <- removePunctuation(tolower(cons_concat))

pros_concat_table <- table(strsplit(pros_concat_clean," ")) %>%
  as_tibble(.name_repair = "minimal") %>%
  setNames(., c("Var1", "n")) %>%
  arrange(desc(n)) %>%
  anti_join(stop_words,by=c("Var1" = "word")) %>% # Removing common words
  anti_join(stop_words_custom,by=c("Var1" = "word")) # Removing common words

cons_concat_table <- table(strsplit(cons_concat_clean," ")) %>%
  as_tibble(.name_repair = "minimal") %>%
  setNames(., c("Var1", "n")) %>%
  arrange(desc(n)) %>%
  anti_join(stop_words,by=c("Var1" = "word")) %>% # Removing common words
  anti_join(stop_words_custom,by=c("Var1" = "word")) # Removing common words

# Counting two-word phrases
pros_concat_table_bi <- tibble(text=pros_concat_clean) %>%
  unnest_tokens(bigram,text,token="ngrams",n=2) %>%
  separate(bigram,c("word1","word2"),sep=" ") %>%
  filter(!word1 %in% stop_words$word,
         !word2 %in% stop_words$word) %>%
  count(word1,word2,sort=TRUE) %>%
  mutate(Var1=paste(word1,word2,sep="-")) %>%
  select(Var1,n)

cons_concat_table_bi <- tibble(text=cons_concat_clean) %>%
  unnest_tokens(bigram,text,token="ngrams",n=2) %>%
  separate(bigram,c("word1","word2"),sep=" ") %>%
  filter(!word1 %in% stop_words$word,
         !word2 %in% stop_words$word) %>%
  count(word1,word2,sort=TRUE) %>%
  mutate(Var1=paste(word1,word2,sep="-")) %>%
  select(Var1,n)

# Counting three-word phrases
pros_concat_table_tri <- tibble(text=pros_concat_clean) %>%
  unnest_tokens(trigram,text,token="ngrams",n=3) %>%
  separate(trigram,c("word1","word2","word3"),sep=" ") %>%
  filter(!word1 %in% stop_words$word,
         !word2 %in% stop_words$word,
         !word3 %in% stop_words$word) %>%
  count(word1,word2,word3,sort=TRUE) %>%
  mutate(Var1=paste(word1,word2,word3,sep="-")) %>%
  select(Var1,n)

cons_concat_table_tri <- tibble(text=cons_concat_clean) %>%
  unnest_tokens(trigram,text,token="ngrams",n=3) %>%
  separate(trigram,c("word1","word2","word3"),sep=" ") %>%
  filter(!word1 %in% stop_words$word,
         !word2 %in% stop_words$word,
         !word3 %in% stop_words$word) %>%
  count(word1,word2,word3,sort=TRUE) %>%
  mutate(Var1=paste(word1,word2,word3,sep="-")) %>%
  select(Var1,n)

# Joining single, double and triple word phrases together
pros_table <- full_join(pros_concat_table,pros_concat_table_bi)
pros_table <- full_join(pros_table,pros_concat_table_tri) %>%
  arrange(desc(n)) %>%
  filter(n>1) %>%
  filter(Var1!="") %>%
  filter(is.na(as.numeric(Var1)) == TRUE)

cons_table <- full_join(cons_concat_table,cons_concat_table_bi)
cons_table <- full_join(cons_table,cons_concat_table_tri) %>%
  arrange(desc(n)) %>%
  filter(n>1) %>%
  filter(Var1!="") %>%
  filter(is.na(as.numeric(Var1)) == TRUE)

#pros_table2 <- pros_table %>% filter(Var1 != "life",Var1 != "balance")

set.seed(142)
png(paste0(folder, company_name," Pros wordcloud.png"), width=1280,height=800,res=144)
pro_wordcloud <- wordcloud(words=pros_table$Var1,freq=pros_table$n,min.freq=1,max.words=200,random.order=FALSE,rot.per=0,colors=brewer.pal(8, "Dark2"))
dev.off()

png(paste0(folder, company_name," Cons wordcloud.png"), width=1280,height=800,res=144)
con_wordcloud <- wordcloud(words=cons_table$Var1,freq=cons_table$n,min.freq=1,max.words=200,random.order=FALSE,rot.per=0,colors=brewer.pal(8, "Dark2"))
dev.off()

write_csv(pros_table,paste0(folder, company_name," Pros Table.csv"))
write_csv(cons_table,paste0(folder, company_name," Cons Table.csv"))

write_csv(clean_tibble,paste0(folder, company_name," Full site scrape.csv"))